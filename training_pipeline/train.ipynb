{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train different classifiers on still image datasets and visualize their outputs/performance\n",
    "\n",
    "PARAMETERS\n",
    "* detection confidence  -  check from realtime detection\n",
    "* tracking confidence  -  check from realtime detection\n",
    "* presence confidence  -  check from realtime detection\n",
    "* CLASSIFIER: random forest - n_estimators\n",
    "\n",
    "class balancing or classifier does not do much - seems to be a matter of the\n",
    "kyepoint detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "from prepare_data import parse_image_folder\n",
    "from extract_features import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "seed = 333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the Gemini API\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 2754\n"
     ]
    }
   ],
   "source": [
    "# still image dataset path\n",
    "directory = \"/Users/alejandraduran/Documents/Pton_courses/COS429/COS429_final_project/image_data\"\n",
    "\n",
    "# get standardized images and labels\n",
    "X, labels, df = parse_image_folder(directory)\n",
    "\n",
    "print('Number of images:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733701873.223434 50116083 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 86), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1749\n"
     ]
    }
   ],
   "source": [
    "# extract landmarks: MEDIAPIPE \n",
    "min_pose_detection_confidence = 0.5  # biggest effect\n",
    "min_pose_presence_confidence = 0.5\n",
    "min_tracking_confidence = 0.8\n",
    "\n",
    "mp_model_path = \"../pretrained_models/pose_landmarker_full.task\"\n",
    "detector = mediapipe_detector(mp_model_path,\n",
    "                              min_pose_detection_confidence=min_pose_detection_confidence,\n",
    "                              min_pose_presence_confidence=min_pose_presence_confidence,\n",
    "                              min_tracking_confidence=min_tracking_confidence,)\n",
    "\n",
    "x_data = np.zeros((len(X), MP_N_LANDMARKS * 4))  # For pose landmarks\n",
    "y_data = np.zeros(labels.shape)  # For labels\n",
    "\n",
    "c = 0\n",
    "\n",
    "# run inference on every image\n",
    "for i in range(len(X)):\n",
    "    landmarks = mediapipe_detect(detector, X[i])\n",
    "    # only include images with detected landmarks\n",
    "    if landmarks is not None:\n",
    "        # with detected poses\n",
    "        if len(landmarks.pose_landmarks) != 0:\n",
    "            x_data[i], y_data[i] = mediapipe_format_landmark(landmarks, labels[i])\n",
    "            \n",
    "            # draw one example detection\n",
    "            if c < 100:\n",
    "                annotated_image = draw_landmarks_on_image(X[i], landmarks)\n",
    "                cv2.imwrite(f'visualize_landmarks/{i}.jpg', cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))     \n",
    "                c += 1                        \n",
    "\n",
    "# drop images with no landmarks detected\n",
    "non_zero_mask = np.any(x_data != 0, axis=1)\n",
    "x_data = x_data[non_zero_mask]\n",
    "y_data = y_data[y_data != 0]\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.2, shuffle=True, random_state=seed\n",
    ")\n",
    "\n",
    "print('Number of training samples:', len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the landmark training datasets\n",
    "\n",
    "with open(f'landmark_datasets/landmark_train_{min_pose_detection_confidence}_{min_pose_presence_confidence}_{min_tracking_confidence}.pkl', 'wb') as f:\n",
    "    pickle.dump([X_train, y_train], f)\n",
    "    \n",
    "with open(f'landmark_datasets/landmark_test_{min_pose_detection_confidence}_{min_pose_presence_confidence}_{min_tracking_confidence}.pkl', 'wb') as f:\n",
    "    pickle.dump([X_test, y_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples after SMOTE: 3478\n"
     ]
    }
   ],
   "source": [
    "# class balancing - not necessarily better\n",
    "smote_k_neighbors = 3  \n",
    "smote = SMOTE(random_state=seed, k_neighbors=smote_k_neighbors)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# save class distributions before and after rebalancing\n",
    "y_before_rebalance = pd.Series(y_train).value_counts()\n",
    "y_after_rebalance = pd.Series(y_resampled).value_counts()\n",
    "with open(f'rebalancing_analysis/SMOTE_{smote_k_neighbors}.pkl', 'wb') as f:\n",
    "    pickle.dump((y_before_rebalance, y_after_rebalance), f)\n",
    "    \n",
    "print('Number of training samples after SMOTE:', len(X_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train classifier \n",
    "# forest_n_estimators = 300  # upper bound here\n",
    "# forest = RandomForestClassifier(n_estimators=forest_n_estimators, random_state=seed, verbose=1)\n",
    "# forest.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # save the model\n",
    "# with open(f'../trained_classifiers/random_forest.pkl', 'wb') as f:\n",
    "#     pickle.dump(forest, f)\n",
    "\n",
    "# # train a very simple neural network to get the classification\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# nn = MLPClassifier(random_state=seed, \n",
    "#                    max_iter=2000, \n",
    "#                    alpha =0.001,\n",
    "#                    learning_rate_init = 0.001,\n",
    "#                    hidden_layer_sizes=(100,50,100,50),)\n",
    "# nn.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # # save the model\n",
    "# # with open(f'../trained_classifiers/neural_network.pkl', 'wb') as f:\n",
    "# #     pickle.dump(nn, f)\n",
    "\n",
    "# # train another type of classifier\n",
    "# from sklearn.svm import SVC\n",
    "# svm = SVC(random_state=seed)\n",
    "# svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # save the model\n",
    "# with open(f'../trained_classifiers/svm.pkl', 'wb') as f:\n",
    "#     pickle.dump(svm, f)\n",
    "\n",
    "# train a classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=seed)\n",
    "gbc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# save the model\n",
    "with open(f'../trained_classifiers/gradient_boosting.pkl', 'wb') as f:\n",
    "    pickle.dump(gbc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediapipe Model Accuracy (with SMOTE): 0.684931506849315\n",
      "Mediapipe Model Accuracy (with SMOTE): 0.3150684931506849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandraduran/opt/anaconda3/envs/cos429/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/alejandraduran/opt/anaconda3/envs/cos429/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "# NOTE: NEWneural_network worked w/o being trained on the last??\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Mediapipe Model Accuracy (with SMOTE): {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
